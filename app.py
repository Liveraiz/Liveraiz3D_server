import os
import sys
import time
import uuid
import glob
import json
import gzip
import zipfile
import logging
import tempfile  
from io import BytesIO

# Flask & Web ê´€ë ¨
from flask import Flask, request, jsonify, send_file, send_from_directory, make_response, Response
from flask_cors import CORS
from werkzeug.utils import secure_filename

# HTTP ìš”ì²­ ê´€ë ¨
import requests
from requests_toolbelt.multipart.encoder import MultipartEncoder
from requests_toolbelt import MultipartEncoderMonitor
from tqdm import tqdm

# ì˜ë£Œ ì˜ìƒ ê´€ë ¨
import pydicom
import nibabel as nib
import nrrd

# ë°ì´í„° ì²˜ë¦¬ & ê³¼í•™ ê³„ì‚°
import numpy as np
from scipy.ndimage import zoom
from skimage import measure
from skimage.measure import marching_cubes

# ë©”ì‹œ ì²˜ë¦¬
import trimesh
from trimesh.smoothing import filter_taubin

# ì‹œê°í™” (ë””ë²„ê¹…ìš©)
import matplotlib.pyplot as plt

app = Flask(__name__, static_url_path='/uploads', static_folder='uploads')
CORS(app, resources={r"/*": {"origins": "*"}})

@app.after_request
def after_request(response):
    response.headers["Access-Control-Allow-Origin"] = "*"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization"
    response.headers.add("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
    return response

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads", "dicom")



# ë¡œê·¸ ì„¤ì • (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

import SimpleITK as sitk
from scipy.ndimage import binary_fill_holes




@app.route("/", methods=["GET"])
def index():
    return {"status": "running", "message": "Flask server is up!"}




# @app.route('/convert-mesh', methods=['OPTIONS', 'POST'])
# def convert_mesh():
#     import scipy.ndimage as ndi
#     try:
#         label_id = int(request.form.get("label", 1))
#         original_mesh_file = request.files.get("original_mesh")
#         edited_mesh_file = request.files.get("edited_mesh")
#         nrrd_file = request.files.get("nrrd_file")

#         logging.info("===== [convert-mesh ìš”ì²­ ìˆ˜ì‹ ] =====")
#         logging.info(f"â–¶ ë¼ë²¨ ID: {label_id}")
#         logging.info(f"â–¶ original_mesh íŒŒì¼: {original_mesh_file.filename}")
#         logging.info(f"â–¶ edited_mesh íŒŒì¼: {edited_mesh_file.filename}")
#         n_bytes = len(nrrd_file.read())
#         logging.info(f"â–¶ NRRD íŒŒì¼ í¬ê¸°: {n_bytes} bytes")

#         nrrd_file.seek(0)
#         with tempfile.NamedTemporaryFile(delete=False, suffix=".nrrd") as tmp:
#             tmp.write(nrrd_file.read())
#             tmp_path = tmp.name

#         seg_image = sitk.ReadImage(tmp_path)
#         seg_data = sitk.GetArrayFromImage(seg_image)  # (Z, Y, X)
#         size = seg_image.GetSize()  # (X,Y,Z)
#         origin = np.array(seg_image.GetOrigin())
#         spacing = np.array(seg_image.GetSpacing())
#         direction = np.array(seg_image.GetDirection()).reshape(3, 3)
#         inv_direction = np.linalg.inv(direction)

#         logging.info("===== [NRRD ë©”íƒ€ë°ì´í„°] =====")
#         logging.info(f"Shape (Z,Y,X): {seg_data.shape}")
#         logging.info(f"Origin (mm): {origin}")
#         logging.info(f"Spacing: {spacing}")
#         logging.info(f"Direction:\n{direction}")

#         # === í¸ì§‘ ë©”ì‰¬ ë¡œë“œ (obj) ===
#         edited_mesh = trimesh.load(edited_mesh_file, file_type='obj')
#         verts_edited = np.array(edited_mesh.vertices)
#         faces_edited = np.array(edited_mesh.faces)
#         verts_edited[:, 0] *= -1
#         verts_edited = verts_edited[:, [0, 2, 1]]
#         logging.info(f"[í¸ì§‘ ë©”ì‹œ] min(mm): {verts_edited.min(0)}, max(mm): {verts_edited.max(0)}, center(mm): {verts_edited.mean(0)}")
#         edited_trimesh = trimesh.Trimesh(vertices=verts_edited, faces=faces_edited, process=True)
#         pitch = float(np.min(spacing)) * 0.8  # ë” ì´˜ì´˜í•˜ê²Œ

#         # === Voxelize mesh ===
#         vox = edited_trimesh.voxelized(pitch=pitch)
#         vox_matrix = vox.matrix.astype(np.uint8)
#         vox_transform = vox.transform  # 4x4 matrix
#         vox_origin = vox_transform[:3, 3]
#         logging.info(f"[voxelized] matrix shape: {vox_matrix.shape}, origin (from transform): {vox_origin}")
#         logging.info(f"[voxelized] bounding box (mm): min {verts_edited.min(0)}, max {verts_edited.max(0)}")
#         logging.info(f"[NRRD bbox] origin {origin}, end {origin + spacing * (np.array(seg_data.shape)[::-1])}")

#         # === Voxel â†’ NRRD ì˜ì—­ ë§¤í•‘ ===
#         mask = np.zeros_like(seg_data, dtype=np.uint8)
#         n_filled = 0
#         z_max, y_max, x_max = vox_matrix.shape
#         idx_debug = []
#         for z in range(z_max):
#             for y in range(y_max):
#                 for x in range(x_max):
#                     if vox_matrix[z, y, x] > 0:
#                         pt_vox = np.array([x, y, z, 1])
#                         pt_mm = (vox_transform @ pt_vox)[:3]   # (mm)
#                         rel_mm = pt_mm - origin
#                         idx_xyz = np.dot(inv_direction, rel_mm) / spacing
#                         idx_zyx = np.round(idx_xyz[::-1]).astype(int)
#                         if n_filled < 10:
#                             idx_debug.append((z, y, x, pt_mm.tolist(), idx_zyx.tolist()))
#                         if (
#                             0 <= idx_zyx[0] < mask.shape[0] and
#                             0 <= idx_zyx[1] < mask.shape[1] and
#                             0 <= idx_zyx[2] < mask.shape[2]
#                         ):
#                             mask[idx_zyx[0], idx_zyx[1], idx_zyx[2]] = 1
#                             n_filled += 1
#         logging.info(f"[mask] voxelized mask sum: {mask.sum()}, n_filled: {n_filled}")
#         for i, row in enumerate(idx_debug):
#             logging.info(f"[debug] voxel({row[0]},{row[1]},{row[2]}) mm={row[3]} â†’ nrrd idx={row[4]}")

#         # ë‚´ë¶€ ì±„ì›€ ë° ë³´ì •
#         mask_filled = ndi.binary_fill_holes(mask).astype(np.uint8)
#         mask_filled = ndi.binary_closing(mask_filled, iterations=1).astype(np.uint8)  # (optional)
#         logging.info(f"[mask] filled mask sum: {mask_filled.sum()}")

#         # ê¸°ì¡´ ë¼ë²¨ ì‚­ì œ & ìƒˆë¡œ í• ë‹¹
#         before_count = np.sum(seg_data == label_id)
#         seg_data[seg_data == label_id] = 0
#         seg_data[mask_filled > 0] = label_id
#         after_count = np.sum(seg_data == label_id)
#         logging.info(f"ë¼ë²¨ {label_id} êµì²´: ì‚­ì œ ì „ {before_count}, ì ìš© í›„ {after_count}")

#         # NRRD ì €ì¥
#         new_image = sitk.GetImageFromArray(seg_data)
#         new_image.CopyInformation(seg_image)

#         with tempfile.NamedTemporaryFile(delete=False, suffix=".nrrd") as tmp_out:
#             sitk.WriteImage(new_image, tmp_out.name)
#             tmp_out.flush()
#             tmp_out.seek(0)
#             result_bytes = tmp_out.read()

#         logging.info("===== [ë³€í™˜ ì™„ë£Œ â†’ NRRD ë°˜í™˜] =====")
#         return Response(result_bytes, mimetype='application/octet-stream')

#     except Exception as e:
#         logging.exception("âŒ convert-mesh ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
#         return jsonify({"success": False, "message": str(e)}), 500




@app.route('/convert-mesh', methods=['OPTIONS', 'POST'])
def convert_mesh():
    try:
        # === ìš”ì²­ íŒŒë¼ë¯¸í„° ===
        label_id = int(request.form.get("label", 1))
        original_mesh_file = request.files.get("original_mesh")
        edited_mesh_file = request.files.get("edited_mesh")
        nrrd_file = request.files.get("nrrd_file")

        logging.info("===== [convert-mesh ìš”ì²­ ìˆ˜ì‹ ] =====")
        logging.info(f"â–¶ ë¼ë²¨ ID: {label_id}")
        logging.info(f"â–¶ original_mesh íŒŒì¼: {original_mesh_file.filename}")
        logging.info(f"â–¶ edited_mesh íŒŒì¼: {edited_mesh_file.filename}")
        logging.info(f"â–¶ NRRD íŒŒì¼ í¬ê¸°: {len(nrrd_file.read())} bytes")

        # === NRRD ë¡œë“œ ===
        nrrd_file.seek(0)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".nrrd") as tmp:
            tmp.write(nrrd_file.read())
            tmp_path = tmp.name

        seg_image = sitk.ReadImage(tmp_path)
        seg_data = sitk.GetArrayFromImage(seg_image)  # (Z, Y, X)
        size = seg_image.GetSize()  # (X,Y,Z)
        origin = np.array(seg_image.GetOrigin())
        spacing = np.array(seg_image.GetSpacing())
        direction = np.array(seg_image.GetDirection()).reshape(3, 3)
        inv_direction = np.linalg.inv(direction)

        logging.info("===== [NRRD ë©”íƒ€ë°ì´í„°] =====")
        logging.info(f"Shape (Z,Y,X): {seg_data.shape}")
        logging.info(f"Origin (mm): {origin}")
        logging.info(f"Spacing: {spacing}")
        logging.info(f"Direction:\n{direction}")

        # ë¼ë²¨ ì¤‘ì‹¬ ê³„ì‚° ê°œì„ 
        old_coords = np.argwhere(seg_data == label_id)
        if old_coords.size > 0:
            old_center_voxel = old_coords.mean(axis=0)
            old_center_mm = origin + np.dot(direction, old_center_voxel[::-1] * spacing)
            logging.info(f"ê¸°ì¡´ ë¼ë²¨ ì¤‘ì‹¬(mm): {old_center_mm}")

        # === ì›ë³¸ ë©”ì‰¬ ë¡œë“œ ===
        original_mesh = trimesh.load(original_mesh_file, file_type='obj')
        verts_original = np.array(original_mesh.vertices)
        verts_original[:, :2] *= -1  # X,Y ë°˜ì „
        orig_center_mm = verts_original.mean(axis=0)
        logging.info(f"ì›ë³¸ ë©”ì‰¬ ì¤‘ì‹¬(mm): {orig_center_mm}")

        # === í¸ì§‘ ë©”ì‰¬ ë¡œë“œ ===
        edited_mesh = trimesh.load(edited_mesh_file, file_type='obj')
        verts_edited = np.array(edited_mesh.vertices)
        # verts_edited[:, :2] *= -1
        verts_edited[:, 0] *= -1
        verts_edited = verts_edited[:, [0, 2, 1]]
        logging.info(f"í¸ì§‘ ë©”ì‰¬ ë²„í…ìŠ¤ ê°œìˆ˜: {len(verts_edited)}")
        logging.info(f"í¸ì§‘ ë©”ì‰¬ ì¤‘ì‹¬(mm): {verts_edited.mean(axis=0)}")

        # í¸ì§‘ ë©”ì‹œ ë¡œë“œ í›„
        logging.info(f"[í¸ì§‘ ë©”ì‹œ] min(mm): {verts_edited.min(0)}, max(mm): {verts_edited.max(0)}, center(mm): {verts_edited.mean(0)}")
        logging.info(f"[í¸ì§‘ ë©”ì‹œ] ìƒ˜í”Œ vertex(mm): {verts_edited[:5].tolist()}")

        # flip ì ìš© ì „/í›„ ëª¨ë‘ ì°ê¸°

        # mm â†’ voxel ë³€í™˜ ì „
        logging.info(f"[mmâ†’voxel] ë³€í™˜ ì „ ìƒ˜í”Œ(mm): {verts_edited[:5].tolist()}")

        # === ì˜¤í”„ì…‹ ì ìš© ===
        if old_center_mm is not None:
            # ë¼ë²¨ì˜ bounding box ê³„ì‚°
            label_coords = np.argwhere(seg_data == label_id)
            label_min = label_coords.min(axis=0)
            label_max = label_coords.max(axis=0)

            # ë©”ì‹œì˜ bounding box ê³„ì‚° (mm â†’ voxel ë³€í™˜ í›„)
            verts_voxel = (inv_direction @ ((verts_edited - origin).T) / spacing[:, None]).T
            verts_voxel_zyx = verts_voxel[:, [2, 1, 0]]
            mesh_min = verts_voxel_zyx.min(axis=0)
            mesh_max = verts_voxel_zyx.max(axis=0)

            # min ì¢Œí‘œë¥¼ ë§ì¶”ëŠ” ì˜¤í”„ì…‹
            offset_voxel = label_min - mesh_min
            verts_edited += offset_voxel[::-1] * spacing  # ZYX â†’ XYZ

            logging.info(f"ì ìš©ëœ ì˜¤í”„ì…‹(mm): {offset_voxel[::-1] * spacing}")

        # === Bounding Box ë¡œê·¸ ===
        logging.info(f"í¸ì§‘ ë©”ì‰¬ BoundingBox(mm): min {verts_edited.min(0)}, max {verts_edited.max(0)}")
        logging.info(f"NRRD BoundingBox(mm): min {origin}, max {origin + spacing * np.array(size)}")

        # === ì¢Œí‘œ(mm) â†’ Voxel Index ë³€í™˜ ===
        logging.info("===== [ì¢Œí‘œ ë³€í™˜ â†’ Voxel Index] =====")
        logging.info(f"ì¢Œí‘œ ë³€í™˜ ì´ì „ ìƒ˜í”Œ(mm): {verts_edited[:5].tolist()}")

        transformed = inv_direction @ ((verts_edited - origin).T)
        indices = (transformed / spacing[:, None]).T  # (N, 3) in XYZ
        indices_int = np.round(indices).astype(int)

        # XYZ â†’ ZYX (NRRD ë°°ì—´ì€ Z,Y,X)
        indices_zyx = indices_int[:, [2, 1, 0]]

        # í•„í„°ë§
        valid_mask = (
            (indices_zyx[:, 0] >= 0) & (indices_zyx[:, 0] < seg_data.shape[0]) &
            (indices_zyx[:, 1] >= 0) & (indices_zyx[:, 1] < seg_data.shape[1]) &
            (indices_zyx[:, 2] >= 0) & (indices_zyx[:, 2] < seg_data.shape[2])
        )
        valid_indices = indices_zyx[valid_mask]

        logging.info(f"mm â†’ voxel float ìƒ˜í”Œ: {indices[:5].round(2).tolist()}")
        logging.info(f"voxel index ë²”ìœ„(Z,Y,X): min {valid_indices.min(0)}, max {valid_indices.max(0)}")
        logging.info(f"ìœ íš¨ ì¸ë±ìŠ¤ ê°œìˆ˜: {len(valid_indices)}")

        # === ë§ˆìŠ¤í¬ ìƒì„± ===
        mask = np.zeros_like(seg_data, dtype=np.uint8)
        for z, y, x in valid_indices:
            mask[z, y, x] = 1
        mask_filled = binary_fill_holes(mask).astype(np.uint8)

        # === ê¸°ì¡´ ë¼ë²¨ ì‚­ì œ & ìƒˆë¡œ í• ë‹¹ ===
        before_count = np.sum(seg_data == label_id)
        seg_data[seg_data == label_id] = 0
        seg_data[mask_filled > 0] = label_id
        after_count = np.sum(seg_data == label_id)
        logging.info(f"ë¼ë²¨ {label_id} êµì²´: ì‚­ì œ ì „ {before_count}, ì ìš© í›„ {after_count}")

        # === NRRD ì €ì¥ ===
        new_image = sitk.GetImageFromArray(seg_data)
        new_image.CopyInformation(seg_image)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".nrrd") as tmp_out:
            sitk.WriteImage(new_image, tmp_out.name)
            tmp_out.flush()
            tmp_out.seek(0)
            result_bytes = tmp_out.read()

        logging.info("===== [ë³€í™˜ ì™„ë£Œ â†’ NRRD ë°˜í™˜] =====")
        return Response(result_bytes, mimetype='application/octet-stream')

    except Exception as e:
        logging.exception("âŒ convert-mesh ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        return jsonify({"success": False, "message": str(e)}), 500













# @app.route('/convert-mesh', methods=['POST'])
# def convert_mesh():
#     # 1. OBJ íŒŒì¼ ë°›ê¸°
#     mesh_file = request.files.get("mesh_file")
#     if not mesh_file:
#         return {"error": "mesh_file not provided"}, 400

#     # 2. ì˜µì…˜ íŒŒë¼ë¯¸í„° ë°›ê¸°
#     dims = request.form.get("dims")
#     spacing = request.form.get("spacing")
#     dims = [int(x) for x in dims.strip("[]").split(",")]
#     spacing = [float(x) for x in spacing.strip("[]").split(",")]

#     # 3. ë©”ì‹œ ë¡œë“œ (trimesh ì‚¬ìš©)
#     mesh = trimesh.load(mesh_file, file_type='obj')

#     # 4. Voxel ë³€í™˜
#     volume = mesh.voxelized(pitch=spacing[0])  # pitch=voxel í¬ê¸°
#     voxel_matrix = volume.matrix.astype(np.uint8) * 1  # 1/0 mask

#     # 5. NRRD ë³€í™˜ (pynrrd)
#     header = {
#         'space': 'left-posterior-superior',
#         'space directions': [[spacing[0],0,0],[0,spacing[1],0],[0,0,spacing[2]]],
#         'kinds': ['domain', 'domain', 'domain']
#     }

#     with BytesIO() as buf:
#         nrrd.write(buf, voxel_matrix, header)
#         buf.seek(0)
#         return Response(buf.read(), mimetype='application/octet-stream')

@app.route('/generate-mesh', methods=['OPTIONS', 'POST'])
def generate_mesh():
    if request.method == 'OPTIONS':
            response = jsonify({'status': 'ok'})
            response.headers.add("Access-Control-Allow-Origin", "*")
            response.headers.add("Access-Control-Allow-Headers", "Content-Type, Authorization")
            response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
            return response
    try:
        file = request.files['file']
        file_bytes = file.read()

        with tempfile.NamedTemporaryFile(suffix=".nrrd", delete=True) as tmp:
            tmp.write(file_bytes)
            tmp.flush()
            data, header = nrrd.read(tmp.name)

        print(header)

        spacing = header.get('space directions', np.eye(3))
        if isinstance(spacing, np.ndarray):
            spacing = np.diag(spacing).tolist()
        else:
            spacing = [5.0, 5.0, 5.0]

        origin = np.array(header.get('space origin', [0, 0, 0]))
        # origin = [0, 0, 0]
        print(f"âœ… Spacing: {spacing}")
        print(f"âœ… Origin: {origin}")

        unique_labels = np.unique(data)
        unique_labels = unique_labels[unique_labels > 0]

        all_verts = []
        label_meshes = []
        scale_factor = 1  # âœ… ì—…ìƒ˜í”Œë§ ë°°ìœ¨

        for label in unique_labels:
            mask = (data == label).astype(np.uint8)
            if np.sum(mask) == 0:
                continue

            # âœ… í•´ìƒë„ ì—…ìƒ˜í”Œë§
            mask_resampled = zoom(mask, scale_factor, order=0)
            spacing_resampled = [s / scale_factor for s in spacing]

            # marching cubes ì‹¤í–‰
            verts, faces, _, _ = marching_cubes(mask_resampled, level=0.5, spacing=spacing_resampled)

            # verts: voxel index ì¢Œí‘œ
            # spacing_resampled: spacing (mm)
            # origin: NRRD origin (mm)

            # # mm ì¢Œí‘œë¡œ ë³€í™˜
            verts_mm = verts # + origin  # directionì´ ë‹¨ìœ„í–‰ë ¬ì¼ ë•Œ

            # # âœ… ìŠ¤ë¬´ë”© ì ìš©
            mesh = trimesh.Trimesh(vertices=verts_mm, faces=faces)
            filter_taubin(mesh, lamb=0.4, nu=-0.53, iterations=15)

            verts = mesh.vertices
            faces = mesh.faces

            # âœ… ì¢Œí‘œê³„ ë³€í™˜
            verts += origin
            # verts[:, 0] *= -1  # L â†’ R
            # verts = verts[:, [0, 1, 2]]

            all_verts.append(verts)
            label_meshes.append({"label": int(label), "verts": verts, "faces": faces})

        # âœ… ì¤‘ì‹¬ ë§ì¶¤
        all_verts_concat = np.vstack(all_verts)
        center = np.mean(all_verts_concat, axis=0)
        print(f"âœ… ì „ì²´ ë©”ì‹œ ì¤‘ì‹¬: {center}")

        meshes = []
        for mesh_data in label_meshes:
            verts = mesh_data["verts"]
            faces = mesh_data["faces"]

            obj_lines = [f"v {v[0]} {v[1]} {v[2]}" for v in verts]
            obj_lines += [f"f {f[0]+1} {f[1]+1} {f[2]+1}" for f in faces]
            obj_data = "\r\n".join(obj_lines)

            meshes.append({"label": mesh_data["label"], "name": f"segment_{mesh_data['label']}", "objData": obj_data})

        return jsonify({"success": True, "meshes": meshes})

    except Exception as e:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", str(e))
        return jsonify({"success": False, "message": str(e)}), 500








@app.route("/infer-dicom-bundle", methods=["POST"])
def infer_dicom_bundle():
    start_time = time.time()
    files = request.files.getlist("dicomFiles")
    logging.info(f"ğŸ“¥ /infer-dicom-bundle ìš”ì²­: DICOM íŒŒì¼ {len(files)}ê°œ")

    if not files:
        logging.warning("âŒ DICOM íŒŒì¼ì´ ì—†ìŒ")
        return jsonify({"success": False, "message": "No DICOM files"}), 400

    # 1. DICOM ë©”ëª¨ë¦¬ ë¡œë”©
    slices = []
    for i, file in enumerate(files):
        try:
            ds = pydicom.dcmread(file.stream)
            slices.append(ds)
        except Exception as e:
            logging.error(f"âŒ DICOM[{i}] ì½ê¸° ì‹¤íŒ¨: {str(e)}")
            return jsonify({"success": False, "message": f"DICOM ì½ê¸° ì‹¤íŒ¨: {str(e)}"}), 400

    if not slices:
        logging.warning("âŒ DICOM slice ì—†ìŒ")
        return jsonify({"success": False, "message": "DICOM slice ì—†ìŒ"}), 400

    # 2. ì„ì‹œ í´ë”ì— ì €ì¥
    with tempfile.TemporaryDirectory() as temp_dcm_dir:
        for i, s in enumerate(slices):
            s.save_as(os.path.join(temp_dcm_dir, f"{i:04d}.dcm"))

        # 3. ë³€í™˜ í•¨ìˆ˜ í˜¸ì¶œ
        with tempfile.NamedTemporaryFile(suffix=".nii.gz") as tmpfile:
            try:
                convert_to_nifti(temp_dcm_dir, tmpfile.name)
                tmpfile.seek(0)
                nii_bytes = tmpfile.read()

                # nii_bytes = convert_lps_to_ras_nii(nii_bytes)

                # with open("test_data/original_lps.nii.gz", "rb") as f:
                #     nii_bytes = f.read()
                logging.info(f"âœ… NIfTI ë³€í™˜ ì™„ë£Œ ({len(nii_bytes) / 1024:.1f} KB)")
            except Exception as e:
                logging.exception("âŒ NIfTI ë³€í™˜ ì‹¤íŒ¨")
                return jsonify({"success": False, "message": f"NIfTI ë³€í™˜ ì‹¤íŒ¨: {str(e)}"}), 500

            # 4. SMC ì¶”ë¡  ìš”ì²­
            encoder = MultipartEncoder(
                fields={"file": ("converted.nii.gz", BytesIO(nii_bytes), "application/octet-stream")}
            )
            monitor = MultipartEncoderMonitor(encoder, lambda m: None)
            headers = {"Content-Type": monitor.content_type}

            try:
                logging.info("ğŸ“¡ SMC ì„œë²„ë¡œ ì¶”ë¡  ìš”ì²­ ì‹œì‘")
                smc_res = requests.post(
                    "https://smc-ssiso-ai.ngrok.app/infer/hcc-pv/?output_format=.nrrd",
                    data=monitor,
                    headers=headers,
                    timeout=(30, 300),
                )
                elapsed = round(time.time() - start_time, 2)

                if smc_res.status_code != 200:
                    logging.error(f"âŒ SMC ì„œë²„ ì˜¤ë¥˜: {smc_res.status_code}, {smc_res.text}")
                    return jsonify({"success": False, "message": f"SMC ì˜¤ë¥˜: {smc_res.text}", "elapsed": elapsed}), 500

                logging.info(f"âœ… SMC ì‘ë‹µ ì™„ë£Œ ({len(smc_res.content) / 1024:.1f} KB), ì²˜ë¦¬ì‹œê°„: {elapsed}s")
                # converted_nrrd_rps = convert_nrrd_to_rps(smc_res.content)

                # 5. zip ë¬¶ê¸°

                zip_buffer = BytesIO()
                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                    zip_file.writestr("converted.nii.gz", nii_bytes)
                    zip_file.writestr("inferred.nrrd", smc_res.content)  # ë³€ê²½ëœ íŒŒì¼ëª…
                    # zip_file.writestr("inferred.nrrd", converted_nrrd_rps)  # ë³€ê²½ëœ íŒŒì¼ëª…
                zip_buffer.seek(0)

                logging.info("ğŸ“¤ zip íŒŒì¼ ìƒì„± ë° í´ë¼ì´ì–¸íŠ¸ ì‘ë‹µ")

                return send_file(
                    zip_buffer,
                    mimetype='application/zip',
                    as_attachment=True,
                    download_name="result_bundle.zip",
                )

            except Exception as e:
                elapsed = round(time.time() - start_time, 2)
                logging.exception("âŒ SMC ìš”ì²­ ì‹¤íŒ¨ ì˜ˆì™¸ ë°œìƒ")
                return jsonify({"success": False, "message": f"SMC ìš”ì²­ ì‹¤íŒ¨: {str(e)}", "elapsed": elapsed}), 500


def convert_to_nifti(dicom_dir: str, output_path: str):
    slices = []
    for filename in sorted(os.listdir(dicom_dir)):
        if filename.lower().endswith(".dcm"):
            path = os.path.join(dicom_dir, filename)
            try:
                ds = pydicom.dcmread(path)
                slices.append(ds)
            except Exception as e:
                logging.warning(f"âŒ DICOM ì½ê¸° ì‹¤íŒ¨: {filename} - {e}")
                continue

    if not slices:
        raise ValueError("DICOM íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # zì¶• ì •ë ¬
    slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))

    # 3D ë°°ì—´ êµ¬ì„± (Z, Y, X)
    volume = np.stack([s.pixel_array for s in slices]).astype(np.int16)
    logging.info(f"ğŸ§Š 3D ë³¼ë¥¨ shape (before transpose): {volume.shape}")
    volume = np.transpose(volume, (2, 1, 0))  # (Z, Y, X) â†’ (X, Y, Z)
    logging.info(f"â†”ï¸ 3D ë³¼ë¥¨ shape (after transpose): {volume.shape}")

    # spacing
    try:
        pixel_spacing = [float(x) for x in slices[0].PixelSpacing]
        z_spacing = abs(float(slices[1].ImagePositionPatient[2]) - float(slices[0].ImagePositionPatient[2]))
        spacing = (pixel_spacing[0], pixel_spacing[1], z_spacing)
    except Exception as e:
        logging.warning(f"âš  spacing ì˜¤ë¥˜: {e}")
        spacing = (1.0, 1.0, 1.0)
    logging.info(f"ğŸ“ spacing (X, Y, Z): {spacing}")

    # ë°©í–¥ í–‰ë ¬ ë° ì›ì  (affine)
    try:
        iop = slices[0].ImageOrientationPatient
        logging.info(f"ğŸ§­ ImageOrientationPatient: {iop}")
        row = np.array(iop[:3])
        col = np.array(iop[3:])
        normal = np.cross(row, col)

        direction = np.array([
            row * spacing[0],
            col * spacing[1],
            normal * spacing[2]
        ]).T
        logging.info(f"ğŸ§® ë°©í–¥ í–‰ë ¬ (LPS):\n{direction}")

        origin = np.array(slices[0].ImagePositionPatient)
        logging.info(f"ğŸ“ ImagePositionPatient (LPS): {origin}")

        # ğŸ‘‰ LPS â†’ RAS ë³€í™˜
        direction, origin = convert_lps_to_ras(direction, origin)
        logging.info(f"ğŸ§® ë°©í–¥ í–‰ë ¬ (RAS):\n{direction}")
        logging.info(f"ğŸ“ Origin (RAS): {origin}")

        affine = np.eye(4)
        affine[:3, :3] = direction
        affine[:3, 3] = origin
        logging.info(f"ğŸ“ affine:\n{affine}")
    except Exception as e:
        logging.warning(f"âš  Affine ê³„ì‚° ì‹¤íŒ¨: {e}")
        affine = np.diag([*spacing, 1.0])

    # NIfTI ìƒì„±
    nifti_img = nib.Nifti1Image(volume, affine)

    # í—¤ë” ì„¸íŒ…
    hdr = nifti_img.header
    hdr['pixdim'][0] = 1.0  # qfac
    hdr['pixdim'][1:4] = list(spacing)

    # quaternion ê¸°ë³¸ íšŒì „ (ë‹¨ìœ„)
    nifti_img.set_qform(affine, code=1)
    hdr['qform_code'] = 1
    hdr['quatern_b'] = 0.0
    hdr['quatern_c'] = 0.0
    hdr['quatern_d'] = 1.0
    hdr['qoffset_x'] = origin[0]
    hdr['qoffset_y'] = origin[1]
    hdr['qoffset_z'] = origin[2]

    # sform ì„¤ì •
    nifti_img.set_sform(affine, code=1)
    hdr['sform_code'] = 1
    hdr['srow_x'] = affine[0].astype(np.float32)
    hdr['srow_y'] = affine[1].astype(np.float32)
    hdr['srow_z'] = affine[2].astype(np.float32)

    hdr['xyzt_units'] = 10  # millimeters

    # ì €ì¥
    nib.save(nifti_img, output_path)
    logging.info(f"ğŸ’¾ NIfTI ì €ì¥ ì™„ë£Œ: {output_path}")

    # í—¤ë” ë¡œê¹…ìš© ì •ì œ
    hdr_dict = {k: str(hdr[k]) for k in hdr.keys()}
    logging.info(f"ğŸ§¾ NIfTI í—¤ë”:\n{json.dumps(hdr_dict, indent=2)}")



def convert_lps_to_ras_nii(nii_bytes):
    """gzip ì••ì¶•ëœ NIfTI(.nii.gz)ë¥¼ LPS â†’ RASë¡œ ë³€í™˜í•˜ì—¬ gzip bytes ë°˜í™˜"""
    with tempfile.NamedTemporaryFile(suffix=".nii.gz") as tmp_in:
        tmp_in.write(nii_bytes)
        tmp_in.flush()

        # 1. nibabel ë¡œë”©
        img = nib.load(tmp_in.name)
        data = img.get_fdata()
        affine = img.affine.copy()

        logging.info("ğŸ“Œ ì›ë³¸ ë°ì´í„° shape: %s", data.shape)
        logging.info("ğŸ“Œ ë³€í™˜ ì „ affine:\n%s", np.array_str(affine, precision=4, suppress_small=True))

        # affine[0, 0] = abs(affine[0, 0])   # R (+X)
        # affine[0, 3] = -abs(affine[0, 3])

        # affine[1, 1] = abs(affine[1, 1])   # A (+Y)
        # affine[1, 3] = -abs(affine[1, 3])

        # affine[2, 2] = abs(affine[2, 2])   # S (+Z)
        # affine[2, 3] = -abs(affine[2, 3])
        logging.info("ğŸ” Yì¶• ë°˜ì „ ì ìš© í›„ affine:\n%s", np.array_str(affine, precision=4, suppress_small=True))

        # 4. NIfTI ê°ì²´ ìƒì„±
        new_img = nib.Nifti1Image(data.astype(np.int16), affine)  # ì›í•˜ëŠ” bitpix ë§ì¶”ê¸° ìœ„í•´ int16ìœ¼ë¡œ ë³€ê²½
        new_img.set_qform(affine, code=1)
        new_img.set_sform(affine, code=1)
        logging.info("ğŸ§± qform/sform ì ìš© ì™„ë£Œ")

        # 5. quaternion ì´ˆê¸°í™” (íšŒì „ ì œê±°)
        new_img.header['quatern_b'] = 0.0
        new_img.header['quatern_c'] = 0.0
        new_img.header['quatern_d'] = 1.0
        logging.info("ğŸ§­ ì¿¼í„°ë‹ˆì–¸ íšŒì „ ì œê±° ì™„ë£Œ")

        # 6. í”½ì…€ í¬ê¸° ë°©í–¥ ì–‘ìˆ˜ ë³´ì •
        new_img.header['pixdim'][1:4] = np.abs(new_img.header['pixdim'][1:4])
        logging.info("ğŸ“ pixdim ë³´ì •: %s", new_img.header['pixdim'][1:4])

        # 7. ë‹¨ìœ„ ì„¤ì •
        new_img.header['xyzt_units'] = 10  # mm ë‹¨ìœ„
        logging.info("ğŸ“ ë‹¨ìœ„ ì„¤ì • ì™„ë£Œ (mm)")

        # 8. ìµœì¢… header ë¡œê·¸
        log_nii_header(new_img)

        # 9. gzip ì••ì¶•í•˜ì—¬ ë°˜í™˜
        with tempfile.NamedTemporaryFile(suffix=".nii.gz") as tmp_out:
            nib.save(new_img, tmp_out.name)
            tmp_out.seek(0)
            return tmp_out.read()

def log_nii_header(img):
    hdr = img.header

    header_dict = {
        "sizeof_hdr": int(hdr["sizeof_hdr"]),
        "datatype": str(int(hdr["datatype"])),
        "bitpix": str(int(hdr["bitpix"])),
        "dim": np.array2string(hdr["dim"]),
        "pixdim": np.array2string(hdr["pixdim"]),
        "qform_code": str(int(hdr["qform_code"])),
        "sform_code": str(int(hdr["sform_code"])),
        "qoffset_x": str(hdr["qoffset_x"]),
        "qoffset_y": str(hdr["qoffset_y"]),
        "qoffset_z": str(hdr["qoffset_z"]),
        "quatern_b": str(hdr["quatern_b"]),
        "quatern_c": str(hdr["quatern_c"]),
        "quatern_d": str(hdr["quatern_d"]),
        "srow_x": np.array2string(hdr["srow_x"]),
        "srow_y": np.array2string(hdr["srow_y"]),
        "srow_z": np.array2string(hdr["srow_z"]),
        "magic": str(hdr["magic"]),
        "xyzt_units": str(int(hdr["xyzt_units"])),
        "vox_offset": str(hdr["vox_offset"]),
        "scl_slope": str(hdr["scl_slope"]),
        "scl_inter": str(hdr["scl_inter"]),
        "intent_code": str(int(hdr["intent_code"])),
        "intent_name": str(hdr["intent_name"]),
        "intent_p1": str(hdr["intent_p1"]),
        "intent_p2": str(hdr["intent_p2"]),
        "intent_p3": str(hdr["intent_p3"]),
        "descrip": str(hdr["descrip"]),
        "aux_file": str(hdr["aux_file"]),
        "glmax": str(int(hdr["glmax"])),
        "glmin": str(int(hdr["glmin"])),
    }

    logging.info("âœ… ë³€í™˜ í›„ NIfTI header:\n%s", json.dumps(header_dict, indent=2))


def convert_nrrd_to_rps(nrrd_bytes):
    """NRRD íŒŒì¼ì˜ X, Yì¶• (LPSâ†’RAS) ë°©í–¥ ë°˜ì „í•˜ì—¬ bytes ë°˜í™˜"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ“¥ NRRD ë°”ì´íŠ¸ ì…ë ¥ ìˆ˜ì‹ , í¬ê¸°: %.2f KB", len(nrrd_bytes) / 1024)

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•´ì„œ ì½ê¸°
    with tempfile.NamedTemporaryFile(suffix=".nrrd") as temp_in:
        temp_in.write(nrrd_bytes)
        temp_in.flush()
        logger.info("ğŸ“„ ì„ì‹œ NRRD íŒŒì¼ ì €ì¥ ìœ„ì¹˜: %s", temp_in.name)

        data, header = nrrd.read(temp_in.name)
        logger.info("ğŸ“Š NRRD shape: %s, dtype: %s", data.shape, data.dtype)
        logger.info("ğŸ§­ ì›ë³¸ ë°©í–¥ ì •ë³´: %s", header.get('space directions'))
        logger.info("ğŸ§­ ì›ë³¸ origin ì •ë³´: %s", header.get('space origin'))

    # âœ… Xì¶• + Yì¶• ë°˜ì „ (ì¢Œìš° + ì•ë’¤)
    # data = data[:, ::-1, :]
    # data = data[::-1, :, :]
    # data = data[::-1, ::-1, :]
    # data = data[:, :, ::-1]
    # data = data[::-1, :, ::-1]
    # âœ… ë°©í–¥ ì •ë³´ ìˆ˜ì •
    # if 'space directions' in header and isinstance(header['space directions'][0], tuple):
    #     direction = list(header['space directions'])
    #     direction[0] = tuple([-v for v in direction[0]])  # X
    #     # direction[1] = tuple([-v for v in direction[1]])  # Y
    #     direction[2] = tuple([-v for v in direction[2]])  # Z
    #     header['space directions'] = tuple(direction)
    #     logger.info("ğŸ§­ ìˆ˜ì •ëœ ë°©í–¥ ì •ë³´: %s", header['space directions'])

    # # âœ… origin ìˆ˜ì •
    # if 'space origin' in header:
    #     origin = list(header['space origin'])
    #     origin[0] = -origin[0]
    #     # origin[1] = -origin[1]
    #     origin[2] = -origin[2]
    #     header['space origin'] = tuple(origin)
    #     logger.info("ğŸ§­ ìˆ˜ì •ëœ origin ì •ë³´: %s", header['space origin'])

    # ê²°ê³¼ë¥¼ gzip ì••ì¶•ëœ NRRDë¡œ ë‹¤ì‹œ ì €ì¥
    out_io = BytesIO()
    with tempfile.NamedTemporaryFile(suffix=".nrrd") as temp_out:
        nrrd.write(temp_out.name, data, header)
        temp_out.seek(0)
        raw_output = temp_out.read()
        out_io.write(raw_output)
        logger.info("ğŸ“¤ ë³€í™˜ ì™„ë£Œ NRRD í¬ê¸°: %.2f KB", len(raw_output) / 1024)

    return out_io.getvalue()





@app.route("/inspect-nifti", methods=["POST"])
def inspect_nifti():
    try:
        file = request.files["file"]

        # íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥ í›„ load
        with tempfile.NamedTemporaryFile(suffix=".nii.gz") as tmpfile:
            tmpfile.write(file.read())
            tmpfile.flush()

            nifti_img = nib.load(tmpfile.name)  # ê²½ë¡œ ê¸°ë°˜ìœ¼ë¡œ ë¡œë“œ
            header = nifti_img.header
            header_info = {key: str(header[key]) for key in header.keys()}

        return jsonify({"success": True, "header": header_info})

    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 400










def convert_lps_to_ras(direction: np.ndarray, origin: np.ndarray):
    """
    DICOM LPS ì¢Œí‘œê³„ë¥¼ RAS ì¢Œí‘œê³„ë¡œ ë³€í™˜.
    ë°©í–¥ í–‰ë ¬ê³¼ originì˜ X, Yì¶• ë¶€í˜¸ë¥¼ ë°˜ì „.
    """
    direction_ras = direction.copy()
    origin_ras = origin.copy()
    
    # X (Lâ†’R), Y (Pâ†’A) ë°©í–¥ ë°˜ì „
    direction_ras[:, 0] *= -1
    direction_ras[:, 1] *= -1
    origin_ras[0] *= -1
    origin_ras[1] *= -1

    return direction_ras, origin_ras









@app.route("/upload-dicom", methods=["POST"])
def upload_dicom():
    folder_name = request.form.get("folder", "default")
    target_dir = os.path.join(UPLOAD_DIR, folder_name)
    os.makedirs(target_dir, exist_ok=True)

    files = request.files.getlist("dicomFiles")
    if not files:
        return jsonify({"success": False, "message": "No files uploaded"}), 400

    file_names = []
    for file in files:
        filename_only = os.path.basename(file.filename)
        save_path = os.path.join(target_dir, filename_only) 
        file.save(save_path)
        file_names.append(filename_only)

    # niivue-manifest ìƒì„±
    manifest_path = os.path.join(target_dir, "niivue-manifest.txt")
    with open(manifest_path, "w") as f:
        f.write("\n".join(file_names))

    manifest_url = f"http://127.0.0.1:5000/uploads/dicom/{folder_name}/niivue-manifest.txt"

    # nii íŒŒì¼ ë³€í™˜ ë° ì €ì¥
    nii_path = os.path.join(target_dir, "converted.nii.gz")
    # flipped_path = os.path.join(target_dir, "converted_flipped.nii.gz")

    nii_exists = os.path.exists(nii_path)
    # flipped_exists = os.path.exists(flipped_path)

    try:

        if not nii_exists:
            convert_to_nifti(target_dir, nii_path)
        else:
            print(f"ì´ë¯¸ ì¡´ì¬: {nii_path}")

        # if not flipped_exists:
        #     flip_nifti_left_right(nii_path, flipped_path)
        # else:
        #     print(f"ì´ë¯¸ ì¡´ì¬: {flipped_path}")

        original = nib.load(nii_path).get_fdata()
        # flipped = nib.load(flipped_path).get_fdata()
        print(" ì™¼ìª½ ëê°’ (ì›ë³¸):", original[0, :, :].mean())
        # print(" ì™¼ìª½ ëê°’ (ë°˜ì „):", flipped[0, :, :].mean())

        nii_url = f"http://127.0.0.1:5000/uploads/dicom/{folder_name}/converted.nii.gz"
        # flipped_url = f"http://127.0.0.1:5000/uploads/dicom/{folder_name}/converted_flipped.nii.gz"
    except Exception as e:
        return jsonify({"success": False, "message": f"NIfTI ë³€í™˜ ì‹¤íŒ¨: {str(e)}"}), 500

    return jsonify({
        "success": True,
        "message": f"{len(files)} files uploaded and converted to NIfTI",
        "manifestUrl": manifest_url,
        "niiUrl": nii_url,
        # "flippedNiiUrl": flipped_url
    })

def flip_nifti_left_right(input_path, output_path):
    img = nib.load(input_path)
    data = img.get_fdata().astype(np.float32)

    flipped_data = np.flip(data, axis=0)

    affine = img.affine.copy()
    affine[0, 0] *= -1
    affine[0, 3] *= -1

    flipped_img = nib.Nifti1Image(flipped_data, affine)
    nib.save(flipped_img, output_path)

    print("ì¢Œìš° ë°˜ì „ëœ NIfTI ì €ì¥ ì™„ë£Œ:", output_path)


@app.route("/upload-and-infer", methods=["POST"])
def upload_and_infer():
    folder_name = request.form.get("folder", "infer")
    target_dir = os.path.join(UPLOAD_DIR, folder_name)
    os.makedirs(target_dir, exist_ok=True)

    print(f"ìš”ì²­ëœ í´ë”: {folder_name}")
    print(f"ì €ì¥ ê²½ë¡œ: {target_dir}")

    files = request.files.getlist("dicomFiles")
    if not files:
        print("ì—…ë¡œë“œëœ DICOM íŒŒì¼ ì—†ìŒ")
        return jsonify({"success": False, "message": "No files uploaded"}), 400

    file_names = []
    for file in files:
        filename = secure_filename(file.filename)
        save_path = os.path.join(target_dir, filename)
        file.save(save_path)
        file_names.append(filename)
        # print(f"ì €ì¥ëœ íŒŒì¼: {filename}")
        inject_phase_info(save_path, phase='PV')

    # inspect_dicom_tags("/Users/kunkioh/workSpace/zerosketch/dicom-server/uploads/dicom/ScalarVolume")
    # phase_guess = guess_phase_from_dicom_folder(target_dir)
    # print(f"ğŸ“Œ ì¶”ì •ëœ ìœ„ìƒ: {phase_guess}")

    nii_path = os.path.join(target_dir, "converted.nii.gz")
    nrrd_path = os.path.join(target_dir, "inferred.nrrd")

    # NIfTI ë³€í™˜
    if not os.path.exists(nii_path):
        try:
            print("DICOM â†’ NIfTI ë³€í™˜ ì‹œì‘")
            convert_to_nifti(target_dir, nii_path)
            print("NIfTI ë³€í™˜ ì™„ë£Œ:", nii_path)
        except Exception as e:
            print("NIfTI ë³€í™˜ ì‹¤íŒ¨:", str(e))
            return jsonify({"success": False, "message": f"NIfTI ë³€í™˜ ì‹¤íŒ¨: {str(e)}"}), 500
    else:
        print("ì´ë¯¸ ë³€í™˜ëœ NIfTI íŒŒì¼ì´ ì¡´ì¬í•¨:", nii_path)

    size_mb = os.path.getsize(nii_path) / (1024 * 1024)
    print(f"NIfTI íŒŒì¼ í¬ê¸°: {size_mb:.2f} MB")
    # SMC ì¶”ë¡  ìš”ì²­
    if not os.path.exists(nrrd_path):
        try:
            print("SMC ì¶”ë¡  ì„œë²„ë¡œ ì „ì†¡ ì¤‘...")
            print("stdout is TTY:", sys.stdout.isatty())
            res = send_large_file_with_progress(nii_path)
            print("SMC ì‘ë‹µ ì½”ë“œ:", res.status_code)

            if res.status_code != 200:
                print("SMC ì„œë²„ ì˜¤ë¥˜ ì‘ë‹µ:", res.text)
                return jsonify({"success": False, "message": f"SMC ì„œë²„ ì—ëŸ¬: {res.text}"}), 500

            with open(nrrd_path, "wb") as out_f:
                out_f.write(res.content)
            print("NRRD ì €ì¥ ì™„ë£Œ:", nrrd_path)
        except requests.exceptions.ReadTimeout:
            print("SMC ì‘ë‹µ ì§€ì—°ìœ¼ë¡œ timeout ë°œìƒ")
            return jsonify({"success": False, "message": "SMC ì‘ë‹µ ì§€ì—°(timeout)"}), 504

        except requests.exceptions.RequestException as e:
            print("SMC ìš”ì²­ ì¤‘ ì—ëŸ¬:", str(e))
            return jsonify({"success": False, "message": f"SMC ì „ì†¡ ì‹¤íŒ¨: {str(e)}"}), 500
    else:
        print("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” NRRD íŒŒì¼ ì‚¬ìš©:", nrrd_path)

    nii_url = f"http://127.0.0.1:5000/uploads/dicom/{folder_name}/converted.nii.gz"
    nrrd_url = f"http://127.0.0.1:5000/uploads/dicom/{folder_name}/inferred.nrrd"

    print("ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ, ê²°ê³¼ ë°˜í™˜")

    return jsonify({
        "success": True,
        "message": "DICOM â†’ NIfTI ë³€í™˜ ë° AI ì¶”ë¡  ì²˜ë¦¬ ì™„ë£Œ",
        "niiUrl": nii_url,
        "nrrdUrl": nrrd_url
    })

def send_large_file_with_progress(nii_path):
    file_size = os.path.getsize(nii_path)
    progress = tqdm(
        total=file_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024,
        desc="Uploading to SMC",
        ncols=80,
        dynamic_ncols=True,
        ascii=True,         # ascii ë°” (#)ë¡œ í‘œì‹œ â€“ í˜¸í™˜ì„± ë³´ì¥
        file=sys.stdout,    # ê°•ì œë¡œ stdout ì§€ì •
        leave=True,
        bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
    )
    def callback(monitor):
        progress.update(monitor.bytes_read - callback.last_bytes)
        callback.last_bytes = monitor.bytes_read
    callback.last_bytes = 0

    encoder = MultipartEncoder(
        fields={"file": ("converted.nii.gz", open(nii_path, "rb"), "application/octet-stream")}
        # fields={"file": ("phase.nii.gz", open(nii_path, "rb"), "application/octet-stream")}
    )

    monitor = MultipartEncoderMonitor(encoder, callback)

    headers = {"Content-Type": monitor.content_type}

    response = requests.post(
        # "https://smc-ssiso-ai.ngrok.app/nifti-to-nrrd",
        "https://smc-ssiso-ai.ngrok.app/infer/hcc-pv/?output_format=.nrrd",
        data=monitor,
        headers=headers,
        timeout=(30, 300),
    )

    progress.close()
    return response

def guess_phase_from_dicom_folder(dicom_dir):
    phases = []

    for filename in sorted(os.listdir(dicom_dir)):
        if filename.lower().endswith('.dcm'):
            path = os.path.join(dicom_dir, filename)
            try:
                ds = pydicom.dcmread(path, stop_before_pixels=True)

                description = ""
                if 'SeriesDescription' in ds:
                    description += ds.SeriesDescription.lower() + " "
                if 'ProtocolName' in ds:
                    description += ds.ProtocolName.lower()

                if 'pv' in description or 'portal' in description:
                    phases.append('PV')
                elif 'ap' in description or 'arterial' in description:
                    phases.append('AP')
                elif 'vp' in description or 'venous' in description:
                    phases.append('VP')
                elif 'dp' in description or 'delay' in description:
                    phases.append('DP')
                elif 'non-contrast' in description or 'nc' in description:
                    phases.append('NC')
                else:
                    phases.append('Unknown')
            except Exception as e:
                print("âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨:", filename, str(e))
                continue

    # ìœ„ìƒë³„ ê°œìˆ˜ ì¹´ìš´íŠ¸
    from collections import Counter
    counter = Counter(phases)
    print("\nğŸ“Š ìœ„ìƒ ë¶„í¬:")
    for phase, count in counter.items():
        print(f"  {phase}: {count}ê°œ")

    # ê°€ì¥ ë§ì€ ìœ„ìƒì„ ì¶”ì • ê²°ê³¼ë¡œ ë°˜í™˜
    if counter:
        main_phase = counter.most_common(1)[0][0]
        print(f"\nê°€ì¥ ì¶”ì •ë˜ëŠ” ìœ„ìƒ: {main_phase}")
        return main_phase
    else:
        print("â— ìœ„ìƒ ì •ë³´ë¥¼ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return "Unknown"

def inspect_dicom_tags(folder):
    for file in sorted(os.listdir(folder)):
        if file.endswith('.dcm'):
            path = os.path.join(folder, file)
            try:
                ds = pydicom.dcmread(path, stop_before_pixels=True)
                print(f"\nğŸ“„ {file}")
                print("  SeriesDescription:", getattr(ds, 'SeriesDescription', 'ì—†ìŒ'))
                print("  ProtocolName     :", getattr(ds, 'ProtocolName', 'ì—†ìŒ'))
            except Exception as e:
                print(f"âŒ ì½ê¸° ì‹¤íŒ¨: {file} - {e}")
            break  # ì²« íŒŒì¼ë§Œ í™•ì¸


def inject_phase_info(file_path, phase='PV'):
    try:
        ds = pydicom.dcmread(file_path)
        if phase == 'PV':
            ds.SeriesDescription = "Portal Venous Phase"
            ds.ProtocolName = "PortalVenous"
        elif phase == 'AP':
            ds.SeriesDescription = "Arterial Phase"
            ds.ProtocolName = "Arterial"
        elif phase == 'VP':
            ds.SeriesDescription = "Venous Phase"
            ds.ProtocolName = "Venous"
        else:
            ds.SeriesDescription = "Unknown Phase"
            ds.ProtocolName = "Unknown"

        ds.save_as(file_path)
        print(f"âœ”ï¸ ìœ„ìƒ ì •ë³´ ì‚½ì… ì™„ë£Œ: {file_path}")
    except Exception as e:
        print(f"âŒ ìœ„ìƒ ì •ë³´ ì‚½ì… ì‹¤íŒ¨: {file_path} - {e}")     

def make_obj_and_mtl_for_4d(data, segment_infos, output_dir, folder_name):
    obj_urls = []
    mtl_lines = []
    num_channels = data.shape[0]
    for ch in range(num_channels):
        ch_mask = data[ch]
        info = segment_infos.get(ch)
        name = info.get('name', f'ch{ch+1}') if info else f'ch{ch+1}'

        # ìƒ‰ìƒ ì •ë³´ í™•ì¸
        if not info or "color" not in info:
            print(f"â—ì±„ë„ {ch+1} ({name}) ì»¬ëŸ¬ ì—†ìŒ, ìŠ¤í‚µ")
            continue
        color = info["color"]
        if len(color) == 1:
            color = [color[0], 0.0, 0.0]
            print(f"[WARN] ì±„ë„ {ch+1} ({name}) ìƒ‰ìƒ ë³´ì •: {color}")
        elif len(color) < 3:
            print(f"[WARN] ì±„ë„ {ch+1} ({name}) ìƒ‰ìƒ ì •ë³´ ë¶€ì¡±, ìŠ¤í‚µ")
            continue

        # 3D ë§ˆìŠ¤í¬ì¸ì§€ í™•ì¸
        if ch_mask.ndim != 3 or np.sum(ch_mask) == 0:
            print(f"[WARN] ì±„ë„ {ch+1} ({name}) ë§ˆìŠ¤í¬ shape={ch_mask.shape}, skip")
            continue

        mesh = trimesh.voxel.ops.matrix_to_marching_cubes(ch_mask, pitch=3.0)
        obj_name = f"segment_{name}.obj"
        obj_path = os.path.join(output_dir, obj_name)
        mesh.export(obj_path)
        obj_urls.append(f"/uploads/meshes/{folder_name}/{obj_name}")

        mtl_lines.append(f"newmtl segment_{name}")
        mtl_lines.append(f"Kd {color[0]} {color[1]} {color[2]}")
        mtl_lines.append("Ka 0 0 0\n")

        with open(obj_path, "r+") as f:
            content = f.read()
            f.seek(0, 0)
            f.write(f"mtllib segments.mtl\nusemtl segment_{name}\n" + content)
    return obj_urls, mtl_lines


def make_obj_and_mtl_for_3d(data, segment_infos, output_dir, folder_name):
    obj_urls = []
    mtl_lines = []
    label_to_info = {}
    for idx, info in segment_infos.items():
        if "label" in info:
            label_to_info[info["label"]] = info

    unique_labels = np.unique(data)
    unique_labels = unique_labels[unique_labels > 0]

    for label_val in unique_labels:
        mask = (data == label_val).astype(np.uint8)
        info = label_to_info.get(label_val)
        if not info or "color" not in info or len(info["color"]) != 3:
            print(f"â—ë¼ë²¨ {label_val} ì»¬ëŸ¬ ì—†ìŒ, ìŠ¤í‚µ (info={info})")
            continue
        color = info["color"]

        if mask.ndim != 3 or np.sum(mask) == 0:
            continue

        mesh = trimesh.voxel.ops.matrix_to_marching_cubes(mask, pitch=3.0)
        # === í‘œë©´ smoothing ì ìš© ===
        mesh = trimesh.smoothing.filter_laplacian(mesh, lamb=0.001, iterations=10)
        # =========================

        obj_name = f"segment_{info.get('name', label_val)}.obj"
        obj_path = os.path.join(output_dir, obj_name)
        mesh.export(obj_path)
        obj_urls.append(f"/uploads/meshes/{folder_name}/{obj_name}")

        mtl_lines.append(f"newmtl segment_{info.get('name', label_val)}")
        mtl_lines.append(f"Kd {color[0]} {color[1]} {color[2]}")
        mtl_lines.append("Ka 0 0 0\n")

        with open(obj_path, "r+") as f:
            content = f.read()
            f.seek(0, 0)
            f.write(f"mtllib segments.mtl\nusemtl segment_{info.get('name', label_val)}\n" + content)
    return obj_urls, mtl_lines


@app.route("/nrrd-to-obj", methods=["POST"])
def nrrd_to_obj_api():
    if 'file' not in request.files:
        return jsonify({"success": False, "message": "NRRD file missing"}), 400

    uploaded_file = request.files['file']
    folder_name = request.form.get("folder", "meshresult")
    output_dir = os.path.join(BASE_DIR, "uploads", "meshes", folder_name)
    os.makedirs(output_dir, exist_ok=True)

    input_path = os.path.join(output_dir, "input.nrrd")
    mtl_path = os.path.join(output_dir, "segments.mtl")

    # 1. ì´ë¯¸ mtl/obj íŒŒì¼ì´ ìˆìœ¼ë©´ íŒ¨ìŠ¤
    obj_paths = sorted(glob.glob(os.path.join(output_dir, "*.obj")))
    if os.path.exists(mtl_path) and obj_paths:
        # íŒŒì¼ ê²½ë¡œë¥¼ URLë¡œ ë³€í™˜
        obj_urls = ["/uploads/meshes/{}/{}".format(folder_name, os.path.basename(p)) for p in obj_paths]
        print(f"ê¸°ì¡´ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ({len(obj_urls)}ê°œ)")
        return jsonify({
            "success": True,
            "objUrls": obj_urls,
            "mtlUrl": f"/uploads/meshes/{folder_name}/segments.mtl"
        })

    # 2. ìƒˆë¡œ ì €ì¥ ë° ë³€í™˜
    uploaded_file.save(input_path)
    print(f"ğŸ“„ ì €ì¥ëœ NRRD: {input_path}")
    data, header = nrrd.read(input_path)
    print("Spacing (space directions):", header.get("space directions"))

    segment_infos = parse_slicer_segment_infos(header)
    print("=== Slicer ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ===")
    for idx, info in sorted(segment_infos.items()):
        print(f"  Segment{idx}: label={info.get('label')}, name={info.get('name')}, color={info.get('color')}")

    obj_urls, mtl_lines = [], []
    if data.ndim == 4:
        print(f"[INFO] Detected 4D NRRD â†’ 3D label map ë³€í™˜ ì¤‘...")
        data3d = convert_4d_nrrd_to_3d_labelmap(data, segment_infos)
        obj_urls, mtl_lines = make_obj_and_mtl(data3d, header, segment_infos, target_dir, folder_name)
    elif data.ndim == 3:
        obj_urls, mtl_lines = make_obj_and_mtl_for_3d(data, segment_infos, output_dir, folder_name)
    else:
        print("â—ì§€ì›í•˜ì§€ ì•ŠëŠ” NRRD shape:", data.shape)

    # MTL ì €ì¥
    with open(mtl_path, "w") as f:
        f.write("\n".join(mtl_lines))

    print(f"ì´ {len(obj_urls)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ìƒ‰ìƒ ì ìš© ì™„ë£Œ")
    for i, obj in enumerate(obj_urls):
        print(f"  â–¶ Segment {i+1} URL: {obj}")

    if not obj_urls:
        print("âŒ ìœ íš¨í•œ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ì–´ OBJ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return jsonify({"success": False, "message": "No valid segments found"}), 400

    return jsonify({
        "success": True,
        "objUrls": obj_urls,
        "mtlUrl": f"/uploads/meshes/{folder_name}/segments.mtl"
    })

def convert_4d_nrrd_to_3d_labelmap(data4d, segment_infos):
    """
    4D NRRD (C, X, Y, Z)ë¥¼ 3D label map (X, Y, Z)ìœ¼ë¡œ ë³€í™˜
    segment_infos: Segment1_LabelValue ë“± ì •ë³´ í™œìš© (ì—†ìœ¼ë©´ index+1 ì‚¬ìš©)
    """
    print(f"[convert_4d_nrrd_to_3d_labelmap] input shape: {data4d.shape}")

    num_channels = data4d.shape[0]
    out_shape = data4d.shape[1:]
    label_map = np.zeros(out_shape, dtype=np.uint8)

    # ê° ì±„ë„ë³„ label ê°’ ì¶”ì¶œ
    channel_label_values = []
    for ch in range(num_channels):
        info = segment_infos.get(ch)
        if info and 'label' in info:
            label_val = int(info['label'])
        else:
            label_val = ch + 1
        channel_label_values.append(label_val)

    # ìš°ì„ ìˆœìœ„: ì±„ë„ ìˆœì„œëŒ€ë¡œ â†’ ë‚˜ì¤‘ ì±„ë„ì´ ë®ì–´ì”€ (ì›í•˜ë©´ ë°˜ëŒ€ ì²˜ë¦¬ë„ ê°€ëŠ¥)
    for ch in range(num_channels):
        ch_mask = data4d[ch] > 0
        label_val = channel_label_values[ch]
        label_map[ch_mask] = label_val

    print(f"[convert_4d_nrrd_to_3d_labelmap] output unique labels: {np.unique(label_map)}")
    return label_map


def send_to_smc(nii_path):
    file_size = os.path.getsize(nii_path)
    progress = tqdm(
        total=file_size,
        unit='B',
        unit_scale=True,
        desc="Uploading to SMC",
        ascii=True,
        ncols=80,
        dynamic_ncols=True,
        file=sys.stdout,
        leave=True,
        bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
    )

    def callback(monitor):
        progress.update(monitor.bytes_read - callback.last_bytes)
        callback.last_bytes = monitor.bytes_read
    callback.last_bytes = 0

    encoder = MultipartEncoder(
        fields={"file": ("converted.nii.gz", open(nii_path, "rb"), "application/octet-stream")}
    )
    monitor = MultipartEncoderMonitor(encoder, callback)

    headers = {"Content-Type": monitor.content_type}

    response = requests.post(
        "https://smc-ssiso-ai.ngrok.app/infer/hcc-pv/?output_format=.nrrd",
        data=monitor,
        headers=headers,
        timeout=(30, 300),
    )

    progress.close()
    return response

def assign_fallback_color(index):
    import matplotlib.pyplot as plt
    cmap = plt.get_cmap("tab20")
    rgb = cmap(index % 20)[:3]
    return [round(c, 3) for c in rgb]

import re
def parse_slicer_segment_infos(header):
    result = {}
    for key, val in header.items():
        if not isinstance(key, str):
            continue
        match = re.match(r"Segment(\d+)_", key)
        if not match:
            continue
        seg_id = int(match.group(1))
        subkey = key.split("_", 1)[1]
        if seg_id not in result:
            result[seg_id] = {}
        result[seg_id][subkey.lower()] = val

    for seg_id, info in result.items():
        color = info.get("color")
        if isinstance(color, str):
            try:
                color = list(map(float, color.strip().split()))
            except:
                color = None
        elif isinstance(color, list):
            color = [float(c) for c in color]
        else:
            color = None

        if not color or len(color) < 3:
            color = assign_fallback_color(seg_id)
            print(f"Segment{seg_id} â†’ fallback color: {color}")

        # â­ [í•µì‹¬] í•­ìƒ 0~1 ìŠ¤ì¼€ì¼ë¡œ ë§ì¶”ê¸°
        if max(color) > 1.0:
            color = [c / 255 for c in color]

        info["color"] = color

        if "label" not in info or info["label"] is None:
            info["label"] = seg_id + 1

    if not result:
        print("â— í—¤ë” ì„¸ê·¸ë¨¼íŠ¸ ì—†ìŒ â†’ fallback ìƒì„±")
        for i in range(1, 31):
            result[i] = {
                "label": i,
                "name": f"Segment{i}",
                "color": assign_fallback_color(i)
            }

    return result

def assign_fallback_color(index):
    """ê¸°ë³¸ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ì—ì„œ ìƒ‰ìƒ ì„ íƒ"""
    cmap = plt.get_cmap('tab20')  # ìµœëŒ€ 20ê°œê¹Œì§€ í™•ì‹¤í•˜ê²Œ êµ¬ë¶„ë¨
    color = cmap(index % 20)[:3]  # RGBA ì¤‘ RGBë§Œ ì‚¬ìš©
    return [round(c, 3) for c in color]  # 0~1 ë²”ìœ„ë¡œ ë°˜ì˜¬ë¦¼

def make_obj_and_mtl(data, header, segment_infos, out_dir, folder_name):
    obj_urls = []
    mtl_lines = []
    labels = np.unique(data)

    mesh_output_dir = out_dir
    directions = header.get("space directions", None)
    if directions is not None:
        spacing = []
        flips = []
        for vec in directions:
            vec = np.array(vec)
            norm = np.linalg.norm(vec)
            spacing.append(norm)

            # ê°€ì¥ í° ì¶• ë°©í–¥ì˜ signìœ¼ë¡œ flip ì—¬ë¶€ ê²°ì •
            max_axis = np.argmax(np.abs(vec))
            flip_sign = np.sign(vec[max_axis])
            flips.append(flip_sign)

        # print(f">>> spacing used for mesh: {spacing}")
        # print(f">>> flips used for mesh: {flips}")
    else:
        spacing = [1.0, 1.0, 1.0]
    # print(">>> spacing used for mesh:", spacing)

    # === HCC-PV label â†’ name ë§¤í•‘ ===
    label_name_mapping = {
        1: "Liver",
        2: "Rt.lobe",
        3: "RAS",
        4: "RPS",
        5: "Lt.lobe",
        6: "LLS",
        7: "LMS",
        8: "Spigelian",
        9: "PV",
        10: "HV",
        11: "Cancer",
        12: "BD"
    }

    # === HCC-PV label â†’ color ë§¤í•‘ === (RGB 0~1)
    label_color_mapping = {
        1: [238/255, 112/255, 70/255],
        2: [238/255, 112/255, 70/255],
        3: [218/255, 108/255, 110/255],
        4: [138/255, 117/255, 231/255],
        5: [211/255, 255/255, 51/255],
        6: [255/255, 147/255, 77/255],
        7: [185/255, 202/255, 99/255],
        8: [79/255, 255/255, 174/255],
        9: [193/255, 157/255, 255/255],
        10: [139/255, 186/255, 255/255],
        11: [234/255, 36/255, 36/255],
        12: [95/255, 170/255, 127/255]
    }

    for label in labels:
        if label == 0:
            continue  # backgroundëŠ” ì œì™¸

        label_int = int(label)
        # === ì´ë¦„ / ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸°
        name = label_name_mapping.get(label_int, f"Segment{label_int}")
        color = label_color_mapping.get(label_int, [0.5, 0.5, 0.5])

        # === ì¶œë ¥ìš© í™•ì¸
        # print(f"[Label={label_int}] name={name}, color={color}")

        # material ì´ë¦„ ë° íŒŒì¼ëª… í†µì¼
        material_name = f"segment_{name.replace(' ', '_')}"
        obj_filename = f"{material_name}.obj"
        obj_path = os.path.join(mesh_output_dir, obj_filename)

        # ë§ˆìŠ¤í¬ ìƒì„±
        mask = (data == label)
        mask_sum = np.sum(mask)
        # print(f"\n[Label={label_int}] mask sum = {mask_sum}")

        # if mask_sum < 1000:
        #     print(f"[Label={label_int}] mask too small â†’ skip")
        #     continue

        # print(f"[Label={label_int}] marching_cubes ì‹œì‘...")
        origin = header.get("space origin", [0.0, 0.0, 0.0])
        # ë©”ì‰¬ ì €ì¥ (material_name í¬í•¨)
        save_mesh_from_volume(mask, obj_path, material_name, spacing=spacing, origin=origin, flips=flips)
        # print(f"Label {label_int}: mask sum = {np.sum(mask)}")
        # MTL ì •ì˜ ì¶”ê°€
        mtl_lines.append(f"newmtl {material_name}")
        mtl_lines.append(f"Kd {color[0]} {color[1]} {color[2]}")
        mtl_lines.append("Ka 0 0 0")
        mtl_lines.append("Ks 0 0 0")
        mtl_lines.append("d 1.0")
        mtl_lines.append("illum 1")
        mtl_lines.append("")

        # URL ë“±ë¡
        obj_urls.append(f"/uploads/dicom/{folder_name}/{obj_filename}")

    return obj_urls, mtl_lines

def save_mesh_from_volume(
    binary_volume: np.ndarray,
    obj_path: str,
    material_name: str = "default",
    spacing=(1.0, 1.0, 1.0),
    origin=(0.0, 0.0, 0.0),
    flips=(1.0, 1.0, 1.0),
    smoothing_iterations: int = 10
):
    if not np.any(binary_volume):
        print(f"skip: ë¹„ì–´ìˆëŠ” ë³¼ë¥¨ì…ë‹ˆë‹¤ -> {obj_path}")
        return

    verts, faces, normals, _ = measure.marching_cubes(binary_volume, level=0.5, spacing=spacing)

    # print(f"[save_mesh_from_volume] verts.shape = {verts.shape}")
    # print(f"[save_mesh_from_volume] faces.shape = {faces.shape}")

    # origin ì ìš©ë§Œ ì‚¬ìš© (flipsëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš© ì•ˆ í•¨ â†’ ë°©í–¥ì´ ê¼¬ì„)
    verts = verts + np.array(origin)
    # print(f"[save_mesh_from_volume] affine ì ìš© í›„ verts min = {verts.min(axis=0)}, max = {verts.max(axis=0)}")

    mesh = trimesh.Trimesh(
        vertices=verts,
        faces=faces,
        vertex_normals=normals,
        process=False
    )

    # if np.sum(binary_volume) > 3000:
    #     print(f"[save_mesh_from_volume] smoothing ì ìš© ì‹œì‘")
    #     mesh = trimesh.smoothing.filter_laplacian(    
    #         mesh,
    #         lamb=0.1,
    #         iterations=10,
    #         implicit_time_integration=True,
    #         volume_constraint=True
    #     )
    #     print(f"[save_mesh_from_volume] smoothing ì ìš© ì™„ë£Œ")
    # else:
    #     print(f"[save_mesh_from_volume] smoothing ì ìš© ì•ˆ í•¨ (ì‘ì€ segment)")
    # print(f"[save_mesh_from_volume] smoothing ì ìš© ì‹œì‘")
    mesh = trimesh.smoothing.filter_laplacian(
        mesh,
        lamb=0.1,
        iterations=5,
        implicit_time_integration=True,
        volume_constraint=True
    )
    # print(f"[save_mesh_from_volume] smoothing ì ìš© ì™„ë£Œ")
    mesh.export(obj_path)
    # print(f"[save_mesh_from_volume] OBJ ì €ì¥ ì™„ë£Œ: {obj_path}")

    # MTL ì ìš©
    with open(obj_path, "r+") as f:
        content = f.read()
        f.seek(0, 0)
        f.write(f"mtllib segments.mtl\nusemtl {material_name}\n" + content)

@app.route("/upload-and-infer-all", methods=["POST"])
def upload_and_infer_all():
    t_start = time.time()

    folder_name = request.form.get("folder")
    if not folder_name:
        return jsonify({"success": False, "message": "folder ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

    target_dir = os.path.join(UPLOAD_DIR, folder_name)
    os.makedirs(target_dir, exist_ok=True)
    print(f"[1/6] í´ë” ìƒì„± í™•ì¸: {target_dir}")
    # DICOM ì—…ë¡œë“œ (ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ê±´ë„ˆëœ€)
    files = request.files.getlist("dicomFiles")
    saved = 0
    for file in files:
        filename = secure_filename(file.filename)
        save_path = os.path.join(target_dir, filename)
        if not os.path.exists(save_path):
            file.save(save_path)
            saved += 1
    print(f"[2/6] DICOM {saved}/{len(files)}ê°œ ì €ì¥ ì™„ë£Œ")
    # NIfTI ë³€í™˜
    nii_path = os.path.join(target_dir, "converted.nii.gz")
    if not os.path.exists(nii_path):
        t1 = time.time()
        convert_to_nifti(target_dir, nii_path)
        print(f"[3/6] NIfTI ë³€í™˜ ì™„ë£Œ ({round(time.time() - t1, 2)}ì´ˆ)")
    else:
        print(f"[3/6] NIfTI ì´ë¯¸ ì¡´ì¬: {nii_path}")

    # ì¶”ë¡  (SMC í˜¸ì¶œ)
    nrrd_path = os.path.join(target_dir, "inferred.nrrd")
    if not os.path.exists(nrrd_path):
        t2 = time.time()
        res = send_to_smc(nii_path)
        if res.status_code != 200:
            print("[ì˜¤ë¥˜] SMC ì¶”ë¡  ì‹¤íŒ¨")
            return jsonify({"success": False, "message": "SMC server error"}), 500
        with open(nrrd_path, "wb") as f:
            f.write(res.content)
        print(f"[4/6] SMC ì¶”ë¡  ì™„ë£Œ ({round(time.time() - t2, 2)}ì´ˆ)")
    else:
        print(f"[4/6] NRRD ì´ë¯¸ ì¡´ì¬: {nrrd_path}")

    # â˜… segment_infos í•­ìƒ ë¯¸ë¦¬ ë¡œë“œí•˜ê¸° â†’ NameError ë°©ì§€
    data, header = nrrd.read(nrrd_path)
    segment_infos = parse_slicer_segment_infos(header)

    labels = np.unique(data)
    label_name_mapping = {
        1: "Liver",
        2: "Rt.lobe",
        3: "RAS",
        4: "RPS",
        5: "Lt.lobe",
        6: "LLS",
        7: "LMS",
        8: "Spigelian",
        9: "PV",
        10: "HV",
        11: "Cancer",
        12: "BD"
    }

    print("\n[INFO] í¬í•¨ëœ ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡:")
    for label in labels:
        if label == 0:
            continue  # background ìƒëµ
        name = label_name_mapping.get(label, f"UnknownLabel{label}")
        print(f"  - Label {int(label)}: {name}")

    # NRRD â†’ OBJ/MTL ë³€í™˜
    obj_urls = []
    mtl_lines = []
    mtl_path = os.path.join(target_dir, "segments.mtl")

    if os.path.exists(mtl_path):
        print("[5/6] OBJ/MTL íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ê±´ë„ˆëœ€")
        for file in os.listdir(target_dir):
            if file.endswith(".obj"):
                obj_urls.append(f"/uploads/dicom/{folder_name}/{file}")
        with open(mtl_path, "r") as f:
            mtl_lines = f.read().splitlines()
    else:
        t3 = time.time()
        obj_urls, mtl_lines = make_obj_and_mtl(data, header, segment_infos, target_dir, folder_name)
        print(f"[5/6] OBJ ì„¸ê·¸ë¨¼íŠ¸ {len(obj_urls)}ê°œ ìƒì„± ì™„ë£Œ ({round(time.time() - t3, 2)}ì´ˆ)")

        with open(mtl_path, "w") as f:
            f.write("\n".join(mtl_lines))
        print(f"[6/6] MTL ì €ì¥ ì™„ë£Œ: {mtl_path}")

    total_sec = round(time.time() - t_start, 2)
    print(f"[ì™„ë£Œ] ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_sec}ì´ˆ")

    # labelColorMap êµ¬ì„±
    labelColorMap = {}
    for idx, info in segment_infos.items():
        label_name = info.get("name", f"Segment{idx}")
        color = info.get("color", [0.5, 0.5, 0.5])
        color255 = [int(c * 255) for c in color] + [255]  # alpha 255 ê³ ì •
        labelColorMap[f"{label_name}"] = color255

    return jsonify({
        "success": True,
        "niiUrl": f"/uploads/dicom/{folder_name}/converted.nii.gz",
        "nrrdUrl": f"/uploads/dicom/{folder_name}/inferred.nrrd",
        "objUrls": obj_urls,
        "mtlUrl": f"/uploads/dicom/{folder_name}/segments.mtl",
        "labelColorMap": labelColorMap,
        "volumeTable": {
            "columns": [],
            "rows": []
    }
    })

app.run(host="0.0.0.0", port=5051, debug=False, use_reloader=True)